<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Eks | A D Vishnu Prasad]]></title>
  <link href="http://advishnuprasad.github.io/blog/categories/eks/atom.xml" rel="self"/>
  <link href="http://advishnuprasad.github.io/"/>
  <updated>2024-02-23T12:00:53+05:30</updated>
  <id>http://advishnuprasad.github.io/</id>
  <author>
    <name><![CDATA[A D Vishnu Prasad]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Locust in Kubernetes for Performance Testing: A Powerful Combination]]></title>
    <link href="http://advishnuprasad.github.io/blog/2024/02/23/locust-in-kubernetes/"/>
    <updated>2024-02-23T11:48:08+05:30</updated>
    <id>http://advishnuprasad.github.io/blog/2024/02/23/locust-in-kubernetes</id>
    <content type="html"><![CDATA[<p>Performance testing ensures your applications gracefully handle the anticipated—and even the unanticipated—demands of real-world use. Locust, an open-source load testing framework, and Kubernetes, a container orchestration system, offer a potent mix for streamlining and scaling your performance testing efforts.</p>

<h3>Why Locust?</h3>

<p><strong>Python Power</strong>: Locust uses Python to define user behavior, making test creation intuitive and flexible. If you can code it, Locust can simulate it.</p>

<p><strong>Distributed Testing</strong>: Effortlessly simulate massive numbers of concurrent users by running Locust in a distributed mode.</p>

<p><strong>Elegant Web UI</strong>: Monitor your tests in real-time, gain deep insights into performance metrics, and identify bottlenecks thanks to Locust&rsquo;s user-friendly interface.</p>

<h3>Why Kubernetes?</h3>

<p><strong>Scalability</strong>: Seamlessly provision and manage the resources your Locust deployment needs. Spin up workers as required and scale down when testing is complete.</p>

<p><strong>Resilience</strong>: Kubernetes protects your test environment. If a worker node goes down, it automatically restarts pods, minimizing test disruption.</p>

<p><strong>Portability</strong>: Replicate your Locust test infrastructure across different environments (testing, staging, production) with ease.</p>

<p><img src="/images/locust.jpg" alt="Locust UI" /></p>

<h3>Step 1 : Create kubernetes manifests</h3>

<pre><code>---
apiVersion: v1
kind: ConfigMap
metadata:
  name: locust-script-cm
data:
  locustfile.py: |
    from locust import HttpUser, between, task
    import time


    class Quickstart(HttpUser):
        wait_time = between(1, 5)

        @task
        def google(self):
            self.client.request_name = "google"
            self.client.get("https://google.com/")

        @task
        def microsoft(self):
            self.client.request_name = "microsoft"
            self.client.get("https://microsoft.com/")

        @task
        def facebook(self):
            self.client.request_name = "facebook"
            self.client.get("https://facebook.com/")
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
  labels:
    role: locust-master
    app: locust-master
  name: locust-master
spec:
  replicas: 1
  selector:
    matchLabels:
      role: locust-master
      app: locust-master
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      labels:
        role: locust-master
        app: locust-master
    spec:
      containers:
      - image: locustio/locust
        imagePullPolicy: Always
        name: master
        args: ["--master"]
        volumeMounts:
          - mountPath: /home/locust
            name: locust-scripts
        ports:
        - containerPort: 5557
          name: bind
        - containerPort: 5558
          name: bind-1
        - containerPort: 8089
          name: web-ui
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      volumes:
      - name: locust-scripts
        configMap:
          name: locust-script-cm
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
  labels:
    role: locust-worker
    app: locust-worker
  name: locust-worker
spec:
  replicas: 1 # Scale it as per your need
  selector:
    matchLabels:
      role: locust-worker
      app: locust-worker
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      labels:
        role: locust-worker
        app: locust-worker
    spec:
      containers:
      - image: locustio/locust
        imagePullPolicy: Always
        name: worker
        args: ["--worker", "--master-host=locust-master"]
        volumeMounts:
          - mountPath: /home/locust
            name: locust-scripts
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        resources:
          requests:
            memory: "1Gi"
            cpu: "1"
          limits:
            memory: "1Gi"
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      volumes:
      - name: locust-scripts
        configMap:
          name: locust-script-cm
---
apiVersion: v1
kind: Service
metadata:
  labels:
    role: locust-master
  name: locust-master
spec:
  type: ClusterIP
  ports:
  - port: 5557
    name: master-bind-host
  - port: 5558
    name: master-bind-host-1
  selector:
    role: locust-master
    app: locust-master
---
apiVersion: v1
kind: Service
metadata:
  labels:
    role: locust-ui
  name: locust-ui
spec:
  type: LoadBalancer
  ports:
  - port: 8089
    targetPort: 8089
    name: web-ui
  selector:
    role: locust-master
    app: locust-master
</code></pre>

<h3>Step 2 : Scale</h3>

<p>If you want to scale more worker to support more requests per seconds, you can do that by just scaling up the worker pods</p>

<pre><code>kubectl scale --replicas=5 deploy/locust-worker -n locust
</code></pre>

<pre><code>locust-master-74c9f6db7c-klk4l   1/1     Running   0          18m
locust-worker-6674d66d5-kgxlp    1/1     Running   0          6s
locust-worker-6674d66d5-m8bdf    1/1     Running   0          6s
locust-worker-6674d66d5-r9v7p    1/1     Running   0          6s
locust-worker-6674d66d5-z2w4x    1/1     Running   0          6s
locust-worker-6674d66d5-zfswz    1/1     Running   0          19m
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Understanding Kubernetes Update Strategies for Deployments]]></title>
    <link href="http://advishnuprasad.github.io/blog/2022/10/05/understanding-kubernetes-update-strategies-for-deployments/"/>
    <updated>2022-10-05T10:21:47+05:30</updated>
    <id>http://advishnuprasad.github.io/blog/2022/10/05/understanding-kubernetes-update-strategies-for-deployments</id>
    <content type="html"><![CDATA[<h2>Introduction:</h2>

<p>Kubernetes has revolutionized the way we deploy and manage applications in modern infrastructure. With its robust orchestration capabilities, Kubernetes offers various strategies to update deployments seamlessly, ensuring high availability and minimal downtime. In this blog post, we will delve into the different update strategies available in Kubernetes and explore their benefits and use cases.</p>

<h2>Rolling Update Strategy:</h2>

<p>The Rolling Update strategy is the default approach used by Kubernetes for deployments. It facilitates the gradual replacement of old instances with new ones, minimizing service disruptions. Rolling updates allow you to define the maximum number of pods unavailable at any given time, ensuring the availability and stability of your application throughout the update process.
Advantages:</p>

<p>Continuous availability of the application during the update process.
Rollbacks can be easily performed by reverting to the previous version.
Fine-grained control over the update process, enabling you to set parameters like the maximum number of pods unavailable and the update speed.</p>

<h3>Use Cases:</h3>

<p>Deployments that require high availability and minimal downtime.
Applications with a large number of replicas, where updating all instances simultaneously is not feasible.</p>

<h2>Blue-Green Deployment:</h2>

<p>Blue-Green deployment is a strategy that involves running two identical environments (blue and green) in parallel. The active traffic is routed to the blue environment while the green environment is updated with the new version. Once the update is complete, traffic is switched to the green environment, making it the active production environment.</p>

<h3>Advantages:</h3>

<p>Reduced downtime as the switch between environments is instantaneous.
Easy rollback by directing traffic back to the blue environment in case of issues.
Effective testing of new versions before making them live.
Use Cases:</p>

<p>Critical applications with zero tolerance for downtime.
Extensive testing requirements before updating the production environment.</p>

<h2>Canary Release:</h2>

<p>Canary release strategy involves deploying a new version of an application to a small subset of users or traffic while keeping the majority on the older version. This allows for gradual monitoring and validation of the new version&rsquo;s performance and stability before rolling it out to the entire user base.
Advantages:</p>

<p>Early identification of issues or bugs in the new version.
Controlled release of new features or updates to a subset of users.
Reduced impact on the overall application in case of problems with the new version.</p>

<h3>Use Cases:</h3>

<p>Applications with a large user base, where it is essential to minimize the risk of widespread issues.
New feature releases that need to be tested and validated before reaching the entire user base.</p>

<h2>Conclusion:</h2>

<p>Kubernetes provides multiple update strategies for deployments, each catering to different requirements and scenarios. Whether you opt for the Rolling Update, Blue-Green Deployment, or Canary Release strategy, it is crucial to consider factors such as downtime tolerance, testing requirements, and the size of the user base. By choosing the appropriate update strategy and leveraging Kubernetes' powerful orchestration capabilities, you can ensure smooth and efficient updates while maintaining the availability and stability of your applications.</p>
]]></content>
  </entry>
  
</feed>
